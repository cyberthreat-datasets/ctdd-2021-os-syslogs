{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import Transformer as tnsf\n",
    "import preprocess as ad\n",
    "\n",
    "importlib.reload(ad)\n",
    "importlib.reload(tnsf)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.width = 400\n",
    "pd.options.display.max_colwidth = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preproccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100.0% of log lines.\n",
      "Parsing done. [Time taken: 0:00:00.412718]\n"
     ]
    }
   ],
   "source": [
    "# Parse from file\n",
    "# Input log file name\n",
    "log_file  = 'HDFS.log'\n",
    "log_source  = 'HDFS'\n",
    "algorithm = 'Spell'\n",
    "ad.parse(log_source, log_file, algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "081109 203518 143 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862906 src: /10.250.19.102:54106 dest: /10.250.19.102:50010\n",
      "081109 203518 35 INFO dfs.FSNamesystem: BLOCK* NameSystem.allocateBlock: /mnt/hadoop/mapred/system/job_200811092030_0001/job.jar. blk_-1608999687919862906\n",
      "081109 203519 143 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862906 src: /10.250.10.6:40524 dest: /10.250.10.6:50010\n",
      "081109 203519 145 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862906 src: /10.250.14.224:42420 dest: /10.250.14.224:50010\n",
      "081109 203519 145 INFO dfs.DataNode$PacketResponder: PacketResponder 1 for block blk_-1608999687919862906 terminating\n",
      "081109 203519 145 INFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_-1608999687919862906 terminating\n",
      "081109 203519 145 INFO dfs.DataNode$PacketResponder: Received block blk_-1608999687919862906 of size 91178 from /10.250.10.6\n",
      "081109 203519 145 INFO dfs.DataNode$PacketResponder: Received block blk_-1608999687919862906 of size 91178 from /10.250.19.102\n",
      "081109 203519 147 INFO dfs.DataNode$PacketResponder: PacketResponder 0 for block blk_-1608999687919862906 terminating\n",
      "081109 203519 147 INFO dfs.DataNode$PacketResponder: Received block blk_-1608999687919862906 of size 91178 from /10.250.14.224\n"
     ]
    }
   ],
   "source": [
    "# Original raw logs\n",
    "N = 10\n",
    "with open(\"../HDFS_Dataset/HDFS.log\") as file:\n",
    "    for i in range(N): print(next(file).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log Key</th>\n",
       "      <th>Message</th>\n",
       "      <th>Occurrences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Receiving block &lt;*&gt; src &lt;*&gt; dest &lt;*&gt;</td>\n",
       "      <td>1723232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>BLOCK* NameSystem.addStoredBlock blockMap updated &lt;*&gt; is added to &lt;*&gt; size &lt;*&gt;</td>\n",
       "      <td>1719741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Received block &lt;*&gt; of size &lt;*&gt; &lt;*&gt;</td>\n",
       "      <td>1713611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>PacketResponder &lt;*&gt; for block &lt;*&gt; &lt;*&gt;</td>\n",
       "      <td>1706728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>Deleting block &lt;*&gt; file &lt;*&gt;</td>\n",
       "      <td>1402047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>BLOCK* NameSystem.delete &lt;*&gt; is added to invalidSet of &lt;*&gt;</td>\n",
       "      <td>1396174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>BLOCK* NameSystem.allocateBlock &lt;*&gt; &lt;*&gt;</td>\n",
       "      <td>575061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>&lt;*&gt; block &lt;*&gt; to &lt;*&gt;</td>\n",
       "      <td>435697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26</td>\n",
       "      <td>&lt;*&gt;Got exception while serving &lt;*&gt; to &lt;*&gt;</td>\n",
       "      <td>356207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Verification succeeded for &lt;*&gt;</td>\n",
       "      <td>120036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>&lt;*&gt; Starting thread to transfer block &lt;*&gt; to &lt;*&gt; &lt;*&gt;</td>\n",
       "      <td>7002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>BLOCK* ask &lt;*&gt; to replicate &lt;*&gt; to datanode s &lt;*&gt; &lt;*&gt;</td>\n",
       "      <td>7002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25</td>\n",
       "      <td>Unexpected error trying to delete block &lt;*&gt;. BlockInfo not found in volumeMap.</td>\n",
       "      <td>5545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11</td>\n",
       "      <td>writeBlock &lt;*&gt; received exception &lt;*&gt;</td>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Receiving empty packet for block &lt;*&gt;</td>\n",
       "      <td>1464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>BLOCK* NameSystem.addStoredBlock Redundant addStoredBlock request received for &lt;*&gt; on &lt;*&gt; size &lt;*&gt;</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13</td>\n",
       "      <td>writeBlock &lt;*&gt; received exception java.io.IOException Could not read from stream</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>Exception in receiveBlock for block &lt;*&gt; java.io.IOException Connection reset by peer</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>Changing block file offset of block &lt;*&gt; from &lt;*&gt; to &lt;*&gt; meta file offset to &lt;*&gt;</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Exception in receiveBlock for block &lt;*&gt; &lt;*&gt;</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30</td>\n",
       "      <td>PendingReplicationMonitor timed out block &lt;*&gt;</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12</td>\n",
       "      <td>PacketResponder &lt;*&gt; &lt;*&gt; Exception &lt;*&gt;</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>32</td>\n",
       "      <td>Adding an already existing block &lt;*&gt;</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>&lt;*&gt;Failed to transfer &lt;*&gt; to &lt;*&gt; got java.io.IOException Connection reset by peer</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>22</td>\n",
       "      <td>writeBlock &lt;*&gt; received exception java.io.IOException Block &lt;*&gt; is valid and cannot be written to.</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>28</td>\n",
       "      <td>Reopen Block &lt;*&gt;</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>31</td>\n",
       "      <td>PacketResponder &lt;*&gt; &lt;*&gt; Exception java.io.InterruptedIOException Interruped while waiting for IO on channel java.nio.channels.SocketChannel[closed]. &lt;*&gt; millis timeout left.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29</td>\n",
       "      <td>BLOCK* Removing block &lt;*&gt; from neededReplications as it does not belong to any file.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>17</td>\n",
       "      <td>writeBlock &lt;*&gt; received exception java.io.IOException Connection reset by peer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>27</td>\n",
       "      <td>PacketResponder &lt;*&gt; &lt;*&gt; Exception java.io.IOException Connection reset by peer</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>21</td>\n",
       "      <td>PacketResponder &lt;*&gt; &lt;*&gt; Exception java.io.IOException Broken pipe</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Log Key                                                                                                                                                                        Message  Occurrences\n",
       "0         2                                                                                                                                           Receiving block <*> src <*> dest <*>      1723232\n",
       "1         6                                                                                                 BLOCK* NameSystem.addStoredBlock blockMap updated <*> is added to <*> size <*>      1719741\n",
       "2         5                                                                                                                                             Received block <*> of size <*> <*>      1713611\n",
       "3         4                                                                                                                                          PacketResponder <*> for block <*> <*>      1706728\n",
       "4        14                                                                                                                                                    Deleting block <*> file <*>      1402047\n",
       "5        24                                                                                                                     BLOCK* NameSystem.delete <*> is added to invalidSet of <*>      1396174\n",
       "6         3                                                                                                                                        BLOCK* NameSystem.allocateBlock <*> <*>       575061\n",
       "7         7                                                                                                                                                           <*> block <*> to <*>       435697\n",
       "8        26                                                                                                                                      <*>Got exception while serving <*> to <*>       356207\n",
       "9        10                                                                                                                                                 Verification succeeded for <*>       120036\n",
       "10        8                                                                                                                           <*> Starting thread to transfer block <*> to <*> <*>         7002\n",
       "11        9                                                                                                                          BLOCK* ask <*> to replicate <*> to datanode s <*> <*>         7002\n",
       "12       25                                                                                                 Unexpected error trying to delete block <*>. BlockInfo not found in volumeMap.         5545\n",
       "13       11                                                                                                                                          writeBlock <*> received exception <*>         3300\n",
       "14       15                                                                                                                                           Receiving empty packet for block <*>         1464\n",
       "15       18                                                                             BLOCK* NameSystem.addStoredBlock Redundant addStoredBlock request received for <*> on <*> size <*>          975\n",
       "16       13                                                                                               writeBlock <*> received exception java.io.IOException Could not read from stream           82\n",
       "17       16                                                                                           Exception in receiveBlock for block <*> java.io.IOException Connection reset by peer           75\n",
       "18       20                                                                                                Changing block file offset of block <*> from <*> to <*> meta file offset to <*>           65\n",
       "19       19                                                                                                                                    Exception in receiveBlock for block <*> <*>           59\n",
       "20       30                                                                                                                                  PendingReplicationMonitor timed out block <*>           47\n",
       "21       12                                                                                                                                          PacketResponder <*> <*> Exception <*>           44\n",
       "22       32                                                                                                                                           Adding an already existing block <*>           10\n",
       "23       23                                                                                              <*>Failed to transfer <*> to <*> got java.io.IOException Connection reset by peer            9\n",
       "24       22                                                                             writeBlock <*> received exception java.io.IOException Block <*> is valid and cannot be written to.            9\n",
       "25       28                                                                                                                                                               Reopen Block <*>            5\n",
       "26       31  PacketResponder <*> <*> Exception java.io.InterruptedIOException Interruped while waiting for IO on channel java.nio.channels.SocketChannel[closed]. <*> millis timeout left.            5\n",
       "27       29                                                                                           BLOCK* Removing block <*> from neededReplications as it does not belong to any file.            4\n",
       "28       17                                                                                                 writeBlock <*> received exception java.io.IOException Connection reset by peer            3\n",
       "29       27                                                                                                 PacketResponder <*> <*> Exception java.io.IOException Connection reset by peer            2\n",
       "30       21                                                                                                              PacketResponder <*> <*> Exception java.io.IOException Broken pipe            2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identified log patterns\n",
    "log_structured = pd.read_csv(\"Spell_result/HDFS/HDFS.log_templates.csv\") \n",
    "log_structured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log sequences are divided based on each unique block_id\n",
    "### Block_ids represent different sessions of log events related to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5 5 22 11 9 11 9 11 9 26 26 26 23 23 23 21 21 21\n",
      "22 5 5 5 11 9 11 9 11 9 26 26 26\n",
      "22 5 5 5 26 26 26 11 9 11 9 11 9 2 3 23 23 23 21 21 21\n",
      "22 5 5 5 11 9 11 9 11 9 26 26 26\n",
      "22 5 5 5 26 26 26 11 9 11 9 11 9 4 3 3 3 4 3 4 3 3 4 3 3 23 23 23 21 21 21\n",
      "22 5 5 5 26 26 26 11 9 11 9 11 9 3 3 4 3 4 3 3 3 4 4 3 3 23 23 23 21 21 21\n",
      "5 22 5 5 26 26 11 9 11 9 11 9 26 23 23 23 21 21 21\n",
      "22 5 5 5 26 26 26 11 9 11 9 11 9 4 4 3 2 23 23 23 21 21 21\n",
      "5 22 5 5 11 9 11 9 11 9 26 26 26 23 23 23 21 21 21\n",
      "5 5 5 22 11 9 11 9 11 9 26 26 26 23 23 23 21 21 21\n"
     ]
    }
   ],
   "source": [
    "# Log sequences \n",
    "# Rows are divided based on each unique block_id\n",
    "# We create a new row when there is a new block_id in the structured event logs\n",
    "N = 10\n",
    "with open(\"../HDFS_Dataset/HDFS/hdfs_train\") as file:  # the a opens it in append mode\n",
    "    for i in range(N):\n",
    "        print(next(file).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--data_dir'], dest='data_dir', nargs=None, const=None, default='Dataset/', type=<class 'str'>, choices=None, help='the directory where training data is stored', metavar=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "sys.argv = ['']\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--log_file', default='hdfs_train', type=str, help='parsed log file')\n",
    "parser.add_argument('--log_normal', default='hdfs_test_normal', type=str, help='parsed log file of normal testing data')\n",
    "parser.add_argument('--log_abnormal', default='hdfs_test_abnormal', type=str, help='parsed log file of abnormal testing data')\n",
    "\n",
    "#     parser.add_argument('--log_file', default='linux_train', type=str, help='parsed log file')\n",
    "#     parser.add_argument('--log_normal', default='linux_test_normal', type=str, help='parsed log file of normal testing data')\n",
    "#     parser.add_argument('--log_abnormal', default='linux_abnormal', type=str, help='parsed log file of abnormal testing data')\n",
    "\n",
    "parser.add_argument('--window_size', default=10, type=int, help='lenght of training window')\n",
    "\n",
    "parser.add_argument('--batch_size', default=512, type=int, help='input batch size for training')\n",
    "parser.add_argument('--epochs', default=10, type=int, help='number of epochs to train')\n",
    "\n",
    "parser.add_argument('--dropout', default=0.2, type=float, help='number of epochs to train')\n",
    "parser.add_argument('--num_layers', default=1, type=int, help='number of encoder and decoders')\n",
    "parser.add_argument('--num_heads', default=1, type=int, help='number of heads')\n",
    "parser.add_argument('--seed', default=1, type=int, help='random seed')\n",
    "\n",
    "parser.add_argument('--num_classes', type=int, help='number of total log keys')\n",
    "parser.add_argument('--num_candidates', default=10, type=int, help='number of predictors sequence as correct predict')\n",
    "\n",
    "parser.add_argument('--federated', default=False, type=bool, help='number of gpus of gpus to train')      \n",
    "parser.add_argument('--num_gpus', default=1, type=int, help='number of gpus of gpus to train')\n",
    "parser.add_argument('--model_dir', default='../Saved_Models', type=str, help='the directory to store the model')\n",
    "parser.add_argument('--data_dir', default='../HDFS_Dataset', type=str, help='the directory where training data is stored')\n",
    "#     parser.add_argument('--data_dir', default='../CTDD_Dataset/Sample_Dataset_Train_Test_Log_Keys', type=str, help='the directory where training data is stored')\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions 46575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step: 1 Loss: 3.817143 Tokens per Sec: 6948.968262\n",
      "Epoch Step: 51 Loss: 0.946231 Tokens per Sec: 40468.000000\n",
      "Number of sessions(Dataset/HDFS/hdfs_test_normal): 14177\n",
      "Number of sessions(Dataset/HDFS/hdfs_test_abnormal): 4123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:27<04:06, 27.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step: 1 Loss: 0.712141 Tokens per Sec: 34675.261719\n",
      "Epoch Step: 51 Loss: 0.522198 Tokens per Sec: 39128.812500\n",
      "Number of sessions(Dataset/HDFS/hdfs_test_normal): 14177\n",
      "Number of sessions(Dataset/HDFS/hdfs_test_abnormal): 4123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:54<03:37, 27.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step: 1 Loss: 0.484894 Tokens per Sec: 40582.390625\n",
      "Epoch Step: 51 Loss: 0.453453 Tokens per Sec: 40397.144531\n",
      "Number of sessions(Dataset/HDFS/hdfs_test_normal): 14177\n",
      "Number of sessions(Dataset/HDFS/hdfs_test_abnormal): 4123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [01:22<03:13, 27.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step: 1 Loss: 0.423567 Tokens per Sec: 32891.164062\n",
      "Epoch Step: 51 Loss: 0.390242 Tokens per Sec: 40302.214844\n",
      "Number of sessions(Dataset/HDFS/hdfs_test_normal): 14177\n",
      "Number of sessions(Dataset/HDFS/hdfs_test_abnormal): 4123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [01:52<02:49, 28.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step: 1 Loss: 0.381471 Tokens per Sec: 33854.265625\n",
      "Epoch Step: 51 Loss: 0.366486 Tokens per Sec: 39633.601562\n",
      "Number of sessions(Dataset/HDFS/hdfs_test_normal): 14177\n",
      "Number of sessions(Dataset/HDFS/hdfs_test_abnormal): 4123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [02:19<02:20, 28.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step: 1 Loss: 0.330020 Tokens per Sec: 39058.265625\n",
      "Epoch Step: 51 Loss: 0.304167 Tokens per Sec: 40545.675781\n",
      "Number of sessions(Dataset/HDFS/hdfs_test_normal): 14177\n",
      "Number of sessions(Dataset/HDFS/hdfs_test_abnormal): 4123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [02:49<01:53, 28.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step: 1 Loss: 0.301740 Tokens per Sec: 31182.916016\n",
      "Epoch Step: 51 Loss: 0.301749 Tokens per Sec: 39929.457031\n",
      "Number of sessions(Dataset/HDFS/hdfs_test_normal): 14177\n",
      "Number of sessions(Dataset/HDFS/hdfs_test_abnormal): 4123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [03:17<01:25, 28.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step: 1 Loss: 0.306118 Tokens per Sec: 35512.433594\n",
      "Epoch Step: 51 Loss: 0.301927 Tokens per Sec: 40550.320312\n",
      "Number of sessions(Dataset/HDFS/hdfs_test_normal): 14177\n",
      "Number of sessions(Dataset/HDFS/hdfs_test_abnormal): 4123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [03:46<00:57, 28.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step: 1 Loss: 0.282745 Tokens per Sec: 36916.996094\n",
      "Epoch Step: 51 Loss: 0.298923 Tokens per Sec: 40009.753906\n",
      "Number of sessions(Dataset/HDFS/hdfs_test_normal): 14177\n",
      "Number of sessions(Dataset/HDFS/hdfs_test_abnormal): 4123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [04:15<00:28, 28.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step: 1 Loss: 0.298570 Tokens per Sec: 34036.003906\n",
      "Epoch Step: 51 Loss: 0.278906 Tokens per Sec: 40211.468750\n",
      "Number of sessions(Dataset/HDFS/hdfs_test_normal): 14177\n",
      "Number of sessions(Dataset/HDFS/hdfs_test_abnormal): 4123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [04:44<00:00, 28.43s/it]\n"
     ]
    }
   ],
   "source": [
    "model = tnsf.train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(../HDFS_Dataset/hdfs_test_normal): 14177\n",
      "Number of sessions(../HDFS_Dataset/hdfs_test_abnormal): 4123\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "sys.argv = ['']\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--log_normal', default='hdfs_test_normal', type=str, help='parsed log file of normal testing data')\n",
    "parser.add_argument('--log_abnormal', default='hdfs_test_abnormal', type=str, help='parsed log file of abnormal testing data')\n",
    "# parser.add_argument('--log_file', default='linux_train', type=str, help='parsed log file')\n",
    "# parser.add_argument('--log_normal', default='linux_test_normal', type=str, help='parsed log file of normal testing data')\n",
    "# parser.add_argument('--log_abnormal', default='linux_abnormal', type=str, help='parsed log file of abnormal testing data')\n",
    "\n",
    "parser.add_argument('--window_size', default=10, type=int, help='lenght of training window')\n",
    "parser.add_argument('--num_candidates', default=10, type=int, help='number of candidates considered correct predict')\n",
    "\n",
    "parser.add_argument('--federated', default=False, type=bool, help='number of gpus of gpus to train')\n",
    "parser.add_argument('--num_gpus', default=1, type=int, help='number of gpus of gpus to train')\n",
    "parser.add_argument('--model_dir', default='../Saved_Models', type=str, help='the directory to store the model')\n",
    "parser.add_argument('--model_file', default='', type=str, help='the file of previously trained model')   \n",
    "parser.add_argument('--data_dir', default='../HDFS_Dataset', type=str, help='the directory where training data is stored')\n",
    "# parser.add_argument('--data_dir', default='../CTDD_Dataset/Sample_Dataset_Train_Test_Log_Keys', type=str, help='the directory where training data is stored')\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "tnsf.test(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Transformer' from 'C:\\\\Users\\\\Luis Selvera\\\\Desktop\\\\Anomaly_Detection_Transformer\\\\Transformer.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create log sequences with 10 log keys\n",
    "WINDOW_SIZE = 10\n",
    "importlib.reload(tnsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Incoming log: tensor(9, device='cuda:0', dtype=torch.int32)\n",
      "Candidate logs:  tensor([22, 15,  8, 27, 16,  5, 21, 26,  9, 11], device='cuda:0')\n",
      "\n",
      "\n",
      "~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~\n",
      "^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Incoming log: tensor(11, device='cuda:0', dtype=torch.int32)\n",
      "Candidate logs:  tensor([20, 22, 21, 27, 16, 18,  5, 26,  9, 11], device='cuda:0')\n",
      "\n",
      "\n",
      "~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~\n",
      "^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Incoming log: tensor(9, device='cuda:0', dtype=torch.int32)\n",
      "Candidate logs:  tensor([ 8, 22, 23, 19, 15, 27, 25, 26, 11,  9], device='cuda:0')\n",
      "\n",
      "\n",
      "~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~\n",
      "^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Incoming log: tensor(3, device='cuda:0', dtype=torch.int32)\n",
      "Candidate logs:  tensor([27, 28, 25, 18, 11, 26,  2, 23,  4,  3], device='cuda:0')\n",
      "\n",
      "\n",
      "~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~\n",
      "^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Incoming log: tensor(3, device='cuda:0', dtype=torch.int32)\n",
      "Candidate logs:  tensor([13, 12,  1,  5, 25,  9,  2, 23,  3,  4], device='cuda:0')\n",
      "\n",
      "\n",
      "~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~\n",
      "^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Incoming log: tensor(4, device='cuda:0', dtype=torch.int32)\n",
      "Candidate logs:  tensor([12, 19,  1,  5, 25,  9,  2, 23,  3,  4], device='cuda:0')\n",
      "\n",
      "\n",
      "~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~\n",
      "^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Incoming log: tensor(3, device='cuda:0', dtype=torch.int32)\n",
      "Candidate logs:  tensor([19, 18, 22, 28, 25,  9, 23,  4,  2,  3], device='cuda:0')\n",
      "\n",
      "\n",
      "~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~\n",
      "^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Incoming log: tensor(4, device='cuda:0', dtype=torch.int32)\n",
      "Candidate logs:  tensor([18, 14, 22, 19, 25,  9,  2, 23,  4,  3], device='cuda:0')\n",
      "\n",
      "\n",
      "~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~\n",
      "^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Incoming log: tensor(3, device='cuda:0', dtype=torch.int32)\n",
      "Candidate logs:  tensor([19, 28, 22, 18, 25,  9,  4, 23,  2,  3], device='cuda:0')\n",
      "\n",
      "\n",
      "~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~\n",
      "^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Incoming log: tensor(3, device='cuda:0', dtype=torch.int32)\n",
      "Candidate logs:  tensor([14, 22, 19, 18, 25,  9,  2, 23,  4,  3], device='cuda:0')\n",
      "\n",
      "\n",
      "~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"../Saved_Models/centralized_models.pt\")\n",
    "model.eval()\n",
    "\n",
    "# Parameter\n",
    "WINDOW_SIZE = 10\n",
    "\n",
    "# Log sequence\n",
    "seq = [22, 5, 5, 5, 26, 26, 26, 11, 9, 11, 9, 11, 9, 3, 3, 4, 3, 4, 3, 3]\n",
    "\n",
    "# Input log sequence\n",
    "src = seq[:WINDOW_SIZE]\n",
    "# Output log sequence\n",
    "tgt = seq[WINDOW_SIZE:]\n",
    "\n",
    "src_mask = Variable(torch.ones(1, 1, WINDOW_SIZE + 1)).to(device)\n",
    "bos = torch.ones((1, ),dtype = int).to(device)\n",
    "\n",
    "t1 = torch.cat((bos, torch.tensor(src, dtype = torch.int).to(device))).unsqueeze(0)\n",
    "t2 = torch.tensor(tgt, dtype = torch.int).to(device).unsqueeze(0)\n",
    "\n",
    "src = Variable(t1, requires_grad =False)\n",
    "tgt = Variable(t2, requires_grad =False)\n",
    "\n",
    "# Predicted log sequence\n",
    "tgt_pred = tnsf.greedy_decode(model, src, src_mask, tgt, WINDOW_SIZE + 1, 1, True, g=10, halt = False, layers = 1, heads = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt = np.reshape(tgt.cpu().detach().numpy(), (10,))\n",
    "tgt = list(tgt)\n",
    "src = list(np.reshape(src.cpu().detach().numpy(), (11,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  | <font size=\"4\">Positive</font>  | <font size=\"4\">Negative</font> |\n",
    "| --- | --- | --- |\n",
    "| <font size=\"4\">**True**</font> | <font size=\"4\">There is a problem and alarm turns on </font>| <font size=\"4\">There is no problem and no alarm </font>|\n",
    "| <font size=\"4\">**False**</font> | <font size=\"4\">There is no problem but alarm turns on</font> | <font size=\"4\">There is a problem but no alarm</font> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal behavior log sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Incoming log: tensor(9, device='cuda:0', dtype=torch.int32)\n",
      "Candidate logs:  tensor([22, 15,  8, 27, 16,  5, 21, 26,  9, 11], device='cuda:0')\n",
      "\n",
      "\n",
      "~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~\n",
      "^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Incoming log: tensor(11, device='cuda:0', dtype=torch.int32)\n",
      "Candidate logs:  tensor([20, 22, 21, 27, 16, 18,  5, 26,  9, 11], device='cuda:0')\n",
      "\n",
      "\n",
      "~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~\n",
      "^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Incoming log: tensor(9, device='cuda:0', dtype=torch.int32)\n",
      "Candidate logs:  tensor([ 8, 22, 23, 19, 15, 27, 25, 26, 11,  9], device='cuda:0')\n",
      "\n",
      "\n",
      "~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~\n",
      "^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Incoming log: tensor(3, device='cuda:0', dtype=torch.int32)\n",
      "Candidate logs:  tensor([27, 28, 25, 18, 11, 26,  2, 23,  4,  3], device='cuda:0')\n",
      "\n",
      "\n",
      "~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~\n",
      "^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Incoming log: tensor(3, device='cuda:0', dtype=torch.int32)\n",
      "Candidate logs:  tensor([13, 12,  1,  5, 25,  9,  2, 23,  3,  4], device='cuda:0')\n",
      "\n",
      "\n",
      "~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~\n",
      "^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Incoming log: tensor(4, device='cuda:0', dtype=torch.int32)\n",
      "Candidate logs:  tensor([12, 19,  1,  5, 25,  9,  2, 23,  3,  4], device='cuda:0')\n",
      "\n",
      "\n",
      "~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~\n",
      "^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Incoming log: tensor(3, device='cuda:0', dtype=torch.int32)\n",
      "Candidate logs:  tensor([19, 18, 22, 28, 25,  9, 23,  4,  2,  3], device='cuda:0')\n",
      "\n",
      "\n",
      "~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~\n",
      "^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Incoming log: tensor(4, device='cuda:0', dtype=torch.int32)\n",
      "Candidate logs:  tensor([18, 14, 22, 19, 25,  9,  2, 23,  4,  3], device='cuda:0')\n",
      "\n",
      "\n",
      "~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~\n",
      "^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Incoming log: tensor(3, device='cuda:0', dtype=torch.int32)\n",
      "Candidate logs:  tensor([19, 28, 22, 18, 25,  9,  4, 23,  2,  3], device='cuda:0')\n",
      "\n",
      "\n",
      "~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~\n",
      "^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Incoming log: tensor(3, device='cuda:0', dtype=torch.int32)\n",
      "Candidate logs:  tensor([14, 22, 19, 18, 25,  9,  2, 23,  4,  3], device='cuda:0')\n",
      "\n",
      "\n",
      "~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~\n",
      "Normal log sequence: true negative\n",
      " tensor([[ 9, 11,  9,  3,  3,  4,  3,  4,  3,  3]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Log sequence\n",
    "seq = [22, 5, 5, 5, 26, 26, 26, 11, 9, 11, 9, 11, 9, 3, 3, 4, 3, 4, 3, 3]\n",
    "\n",
    "# Input log sequence\n",
    "src = seq[:WINDOW_SIZE]\n",
    "# Output log sequence\n",
    "tgt = seq[WINDOW_SIZE:]\n",
    "\n",
    "src_mask = Variable(torch.ones(1, 1, WINDOW_SIZE + 1)).to(device)\n",
    "bos = torch.ones((1, ),dtype = int).to(device)\n",
    "\n",
    "t1 = torch.cat((bos, torch.tensor(src, dtype = torch.int).to(device))).unsqueeze(0)\n",
    "t2 = torch.tensor(tgt, dtype = torch.int).to(device).unsqueeze(0)\n",
    "\n",
    "src = Variable(t1, requires_grad =False)\n",
    "tgt = Variable(t2, requires_grad =False)\n",
    "\n",
    "# Predicted log sequence\n",
    "tgt_pred = tnsf.greedy_decode(model, src, src_mask, tgt, WINDOW_SIZE + 1, 1, True, g=10, halt = True, layers = 1, heads = 1)\n",
    "\n",
    "if -1 in tgt_pred: print(\"Abnormal log sequence: false positive\")\n",
    "else: print(\"Normal log sequence: true negative\\n\", tgt_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abnormal behavior log sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Incoming log: tensor(4, device='cuda:0', dtype=torch.int32)\n",
      "Candidate logs:  tensor([22, 15, 10, 25, 18, 21,  5, 16,  6, 26], device='cuda:0')\n",
      "\n",
      "\n",
      "~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~ ~~~~~~~~~~\n",
      "Abnormal log sequence: true positive\n",
      " tensor([[ 4, -1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#Log sequence\n",
    "\n",
    "seq = [25, 18, 5, 16, 6, 26, 26, 21, 3, 3, 4, 23, 23, 23, 21, 21, 21]\n",
    "\n",
    "# Input log sequence\n",
    "src = seq[:WINDOW_SIZE]\n",
    "# Output log sequence\n",
    "tgt = seq[WINDOW_SIZE:]\n",
    "\n",
    "src_mask = Variable(torch.ones(1, 1, WINDOW_SIZE + 1)).to(device)\n",
    "bos = torch.ones((1, ),dtype = int).to(device)\n",
    "\n",
    "t1 = torch.cat((bos, torch.tensor(src, dtype = torch.int).to(device))).unsqueeze(0)\n",
    "t2 = torch.tensor(tgt, dtype = torch.int).to(device).unsqueeze(0)\n",
    "\n",
    "src = Variable(t1, requires_grad =False)\n",
    "tgt = Variable(t2, requires_grad =False)\n",
    "\n",
    "# Predicted log sequence\n",
    "tgt_pred = tnsf.greedy_decode(model, src, src_mask, tgt, WINDOW_SIZE + 1, 1, True, g=10, halt = True, layers = 1, heads = 1) \n",
    "\n",
    "#If -1 in predicted sequence, anomaly detected\n",
    "if -1 in tgt_pred: \n",
    "    print(\"Abnormal log sequence: true positive\\n\", tgt_pred)\n",
    "#Otherwise, no anomaly was detected\n",
    "else: \n",
    "    print(\"Normal log sequence: false negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find logs that caused anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4, -1]], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3    PacketResponder <*> for block <*> <*>\n",
      "Name: Message, dtype: object\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ad)\n",
    "\n",
    "log_source = \"HDFS\"\n",
    "algorithm = \"Spell\"\n",
    "#Backtrack to logs that caused anomaly\n",
    "ad.backtrace(tgt_pred[0], log_source, algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping between log key and event templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log Key</th>\n",
       "      <th>Message</th>\n",
       "      <th>Occurrences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Receiving block &lt;*&gt; src &lt;*&gt; dest &lt;*&gt;</td>\n",
       "      <td>1723232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>BLOCK* NameSystem.addStoredBlock blockMap upda...</td>\n",
       "      <td>1719741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Received block &lt;*&gt; of size &lt;*&gt; &lt;*&gt;</td>\n",
       "      <td>1713611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>PacketResponder &lt;*&gt; for block &lt;*&gt; &lt;*&gt;</td>\n",
       "      <td>1706728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>Deleting block &lt;*&gt; file &lt;*&gt;</td>\n",
       "      <td>1402047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>BLOCK* NameSystem.delete &lt;*&gt; is added to inval...</td>\n",
       "      <td>1396174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>BLOCK* NameSystem.allocateBlock &lt;*&gt; &lt;*&gt;</td>\n",
       "      <td>575061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>&lt;*&gt; block &lt;*&gt; to &lt;*&gt;</td>\n",
       "      <td>435697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26</td>\n",
       "      <td>&lt;*&gt;Got exception while serving &lt;*&gt; to &lt;*&gt;</td>\n",
       "      <td>356207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Verification succeeded for &lt;*&gt;</td>\n",
       "      <td>120036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>&lt;*&gt; Starting thread to transfer block &lt;*&gt; to &lt;...</td>\n",
       "      <td>7002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>BLOCK* ask &lt;*&gt; to replicate &lt;*&gt; to datanode s ...</td>\n",
       "      <td>7002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25</td>\n",
       "      <td>Unexpected error trying to delete block &lt;*&gt;. B...</td>\n",
       "      <td>5545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11</td>\n",
       "      <td>writeBlock &lt;*&gt; received exception &lt;*&gt;</td>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Receiving empty packet for block &lt;*&gt;</td>\n",
       "      <td>1464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>BLOCK* NameSystem.addStoredBlock Redundant add...</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13</td>\n",
       "      <td>writeBlock &lt;*&gt; received exception java.io.IOEx...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>Exception in receiveBlock for block &lt;*&gt; java.i...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>Changing block file offset of block &lt;*&gt; from &lt;...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Exception in receiveBlock for block &lt;*&gt; &lt;*&gt;</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30</td>\n",
       "      <td>PendingReplicationMonitor timed out block &lt;*&gt;</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12</td>\n",
       "      <td>PacketResponder &lt;*&gt; &lt;*&gt; Exception &lt;*&gt;</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>32</td>\n",
       "      <td>Adding an already existing block &lt;*&gt;</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>&lt;*&gt;Failed to transfer &lt;*&gt; to &lt;*&gt; got java.io.I...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>22</td>\n",
       "      <td>writeBlock &lt;*&gt; received exception java.io.IOEx...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>28</td>\n",
       "      <td>Reopen Block &lt;*&gt;</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>31</td>\n",
       "      <td>PacketResponder &lt;*&gt; &lt;*&gt; Exception java.io.Inte...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29</td>\n",
       "      <td>BLOCK* Removing block &lt;*&gt; from neededReplicati...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>17</td>\n",
       "      <td>writeBlock &lt;*&gt; received exception java.io.IOEx...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>27</td>\n",
       "      <td>PacketResponder &lt;*&gt; &lt;*&gt; Exception java.io.IOEx...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>21</td>\n",
       "      <td>PacketResponder &lt;*&gt; &lt;*&gt; Exception java.io.IOEx...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Log Key                                            Message  Occurrences\n",
       "0         2               Receiving block <*> src <*> dest <*>      1723232\n",
       "1         6  BLOCK* NameSystem.addStoredBlock blockMap upda...      1719741\n",
       "2         5                 Received block <*> of size <*> <*>      1713611\n",
       "3         4              PacketResponder <*> for block <*> <*>      1706728\n",
       "4        14                        Deleting block <*> file <*>      1402047\n",
       "5        24  BLOCK* NameSystem.delete <*> is added to inval...      1396174\n",
       "6         3            BLOCK* NameSystem.allocateBlock <*> <*>       575061\n",
       "7         7                               <*> block <*> to <*>       435697\n",
       "8        26          <*>Got exception while serving <*> to <*>       356207\n",
       "9        10                     Verification succeeded for <*>       120036\n",
       "10        8  <*> Starting thread to transfer block <*> to <...         7002\n",
       "11        9  BLOCK* ask <*> to replicate <*> to datanode s ...         7002\n",
       "12       25  Unexpected error trying to delete block <*>. B...         5545\n",
       "13       11              writeBlock <*> received exception <*>         3300\n",
       "14       15               Receiving empty packet for block <*>         1464\n",
       "15       18  BLOCK* NameSystem.addStoredBlock Redundant add...          975\n",
       "16       13  writeBlock <*> received exception java.io.IOEx...           82\n",
       "17       16  Exception in receiveBlock for block <*> java.i...           75\n",
       "18       20  Changing block file offset of block <*> from <...           65\n",
       "19       19        Exception in receiveBlock for block <*> <*>           59\n",
       "20       30      PendingReplicationMonitor timed out block <*>           47\n",
       "21       12              PacketResponder <*> <*> Exception <*>           44\n",
       "22       32               Adding an already existing block <*>           10\n",
       "23       23  <*>Failed to transfer <*> to <*> got java.io.I...            9\n",
       "24       22  writeBlock <*> received exception java.io.IOEx...            9\n",
       "25       28                                   Reopen Block <*>            5\n",
       "26       31  PacketResponder <*> <*> Exception java.io.Inte...            5\n",
       "27       29  BLOCK* Removing block <*> from neededReplicati...            4\n",
       "28       17  writeBlock <*> received exception java.io.IOEx...            3\n",
       "29       27  PacketResponder <*> <*> Exception java.io.IOEx...            2\n",
       "30       21  PacketResponder <*> <*> Exception java.io.IOEx...            2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mapping between log key and event template\n",
    "log_structured = pd.read_csv(\"Spell_result/HDFS/\" +  \"HDFS.log_templates.csv\") \n",
    "log_structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
